{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Scorecard development case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/Dataset-case.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of missing data points per column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Values**\n",
    "\n",
    "| Column                  | Missing Values |\n",
    "--------------------------|----------------|\n",
    "| emp_length |               3342 |\n",
    "| revol_util |                 33 |\n",
    "| mort_acc |                 2039 |\n",
    "| pub_rec_bankruptcies |       27 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I should not remove any of the columns with missing values because they are all important\n",
    "# Percedence of values missing is as follows:\n",
    "data.isnull().mean().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the target / dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_status is the target variable\n",
    "# Where Default = 1 and Non-Default = 0\n",
    "data['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop loan_status2 column as it is not needed anymore\n",
    "data.drop(columns = ['loan_status_2'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loan_status.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot it as a bar chart\n",
    "data.loan_status.value_counts(normalize=True).sort_values().plot(kind='bar')\n",
    "plt.title('Loan Status')\n",
    "# add Default instead of 1 and Non-Default instead of 0\n",
    "plt.xticks([0, 1], ['Non-Default', 'Default'], rotation=0)\n",
    "# show exact values\n",
    "for i, v in enumerate(data.loan_status.value_counts(normalize=True).sort_values()):\n",
    "    plt.text(i - 0.1, v + 0.01, str(round(v, 2)))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in every column remove spaces and replace with underscore\n",
    "data.columns = data.columns.str.replace(' ', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test (80-20 split)\n",
    "# Use random_state = 42 to ensure that the results are reproducible\n",
    "# Use stratify to ensure that the proportion of good and bad loans is the same in both train and test sets\n",
    "X = data.drop(columns = 'loan_status', axis=1)\n",
    "y = data['loan_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train, X_test = X_train.copy(), X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning / Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_length\n",
    "# Fill in the missing values with 0.\n",
    "def emp_length_converter(df, column):\n",
    "    df[column].fillna(value = 0, inplace = True)\n",
    "\n",
    "# Apply to X_train\n",
    "emp_length_converter(X_train, 'emp_length')\n",
    "\n",
    "X_train['emp_length'].unique()\n",
    "X_train['emp_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue_d\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "# And create a new column as a difference between today and the respective date column\n",
    "def date_converter(df, column):\n",
    "    # store current month\n",
    "    today_date = pd.to_datetime('2023-05-16')\n",
    "    # convert to datetime format\n",
    "    df[column] = pd.to_datetime(df[column], format = \"%b-%y\")\n",
    "    # calculate the difference in months and add to a new column\n",
    "    df['mths_since_' + column] = round(pd.to_numeric((today_date - df[column]) / np.timedelta64(1, 'M')))\n",
    "    # make any resulting -ve values to be equal to the max date\n",
    "    df['mths_since_' + column] = df['mths_since_' + column].apply(lambda x: df['mths_since_' + column].max() if x < 0 else x)\n",
    "    # drop the original date column\n",
    "    df.drop(columns = [column], inplace = True)\n",
    "\n",
    "# apply to X_train\n",
    "date_converter(X_train, 'issue_d')\n",
    "\n",
    "# Check the new columns\n",
    "print(X_train['mths_since_issue_d'].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the new column\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.distplot(X_train['mths_since_issue_d'])\n",
    "plt.title('Months Since Issue Date')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mort_acc column\n",
    "X_train['mort_acc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mort_acc - fill in the missing values with 0\n",
    "# It is better replace the empty values with 0 instead of the mean because the mean is 1.68.\n",
    "def mort_acc_converter(df, column):\n",
    "    df[column].fillna(value = 0, inplace = True)\n",
    "\n",
    "mort_acc_converter(X_train, 'mort_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revol_util column - Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n",
    "X_train['revol_util'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['revol_util'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revol_util\n",
    "# Fill in the missing values with the mean. Because the mean it is more representative than the median.\n",
    "def revol_util_converter(df, column):\n",
    "    df[column].fillna(value = df[column].mean(), inplace = True)\n",
    "\n",
    "revol_util_converter(X_train, 'revol_util')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub_rec_bankruptcies\n",
    "X_train['pub_rec_bankruptcies'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub_rec_bankruptcies column: Number of public record bankruptcies\n",
    "def pub_rec_bankruptcies_converter(df, column):\n",
    "    df[column].fillna(value = 0, inplace = True)\n",
    "\n",
    "pub_rec_bankruptcies_converter(X_train, 'pub_rec_bankruptcies')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First divide training data into categorical and numerical subsets\n",
    "X_train_num = X_train.select_dtypes(include = np.number).copy()\n",
    "X_train_cat = X_train.select_dtypes(include = np.object).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty dictionary to store the results of chi-square test\n",
    "chi_sq_results = {}\n",
    "\n",
    "# loop over all the categorical variables\n",
    "for col in X_train_cat.columns:\n",
    "    chi, pi, dof, expected = chi2_contingency(pd.crosstab(y_train, X_train_cat[col]))\n",
    "\n",
    "    chi_sq_results.setdefault('Feature', []).append(col)\n",
    "    chi_sq_results.setdefault('p-value', []).append(round(pi, 10))\n",
    "\n",
    "\n",
    "# convert the dictionary to a dataframe\n",
    "chi_sq_results = pd.DataFrame(chi_sq_results)\n",
    "\n",
    "# sort the dataframe by p_value\n",
    "chi_sq_results.sort_values(by = 'p-value', ascending = True, ignore_index=True, inplace = True)\n",
    "\n",
    "chi_sq_results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the categorical variable seem to have predictive power"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA F-Statistic for numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since f_class_if does not accept missing values, wee will do a avery crude imputation of missing values\n",
    "X_train_num.fillna(X_train_num.mean(), inplace = True)\n",
    "\n",
    "# Calculate the F Statistic and corresponding p value\n",
    "f_stat, p_value = f_classif(X_train_num, y_train)\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "ANOVA_F_table = pd.DataFrame(data = {'Numerical_Feature': X_train_num.columns.values, 'F-Score': f_stat, 'p values': p_value.round(decimals=10)})\n",
    "ANOVA_F_table.sort_values(by = ['F-Score'], ascending = False, ignore_index = True, inplace = True)\n",
    "ANOVA_F_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pair-wise correlations between the variables\n",
    "corrmat = X_train_num.corr()\n",
    "plt.figure(figsize = (10, 10))\n",
    "sns.heatmap(corrmat, annot = False, square = True, cmap = 'coolwarm');\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ANOVA F-Statistic is used to identify the numerical variables that are most predictive of the target variable.\n",
    "- Those columns are: 'pub_rec', 'emp_length', 'pub_rec_bankruptcies', 'open_acc', 'revol_bal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_columns_list = ['pub_rec', 'emp_length', 'pub_rec_bankruptcies', 'open_acc', 'revol_bal']\n",
    "\n",
    "# def col_to_drop(df, column_list):\n",
    "#     df.drop(columns = column_list, inplace = True)\n",
    "\n",
    "# # apply to X_train\n",
    "# col_to_drop(X_train, drop_columns_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creaty dummy variables for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dummy(df, column_list):\n",
    "#     '''\n",
    "#     This function will create dummy variables for the categorical variables\n",
    "\n",
    "#     df: the dataframe\n",
    "#     column_list: list of categorical columns\n",
    "#     '''\n",
    "#     df_dummies = []\n",
    "#     for col in column_list:\n",
    "#         df_dummies.append(pd.get_dummies(df[col], prefix = col, prefix_sep = ':'))\n",
    "#     df_dummies = pd.concat(df_dummies, axis = 1)\n",
    "#     df = pd.concat([df, df_dummies], axis = 1)\n",
    "#     return df\n",
    "\n",
    "# # apply to X_train\n",
    "# X_train = create_dummy(X_train, ['sub_grade', 'home_ownership', 'verification_status', 'purpose', 'addr_state'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same transformations to the test set\n",
    "emp_length_converter(X_test, 'emp_length')\n",
    "date_converter(X_test, 'issue_d')\n",
    "mort_acc_converter(X_test, 'mort_acc')\n",
    "revol_util_converter(X_test, 'revol_util')\n",
    "pub_rec_bankruptcies_converter(X_test, 'pub_rec_bankruptcies')\n",
    "# col_to_drop(X_test, drop_columns_list) # <<< I don't think this is necessary!\n",
    "\n",
    "# X_test = create_dummy(X_test, ['sub_grade', 'home_ownership', 'verification_status', 'purpose', 'addr_state']) # <<< I don't think this is necessary!\n",
    "\n",
    "# reindex the dummied test set variables to make sure all the feature columns in the train set are also available in the test set\n",
    "X_test = X_test.reindex(labels=X_train.columns, axis=1, fill_value=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight of Evidence (WoE) - Binning / Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will analyze both categorical and numerical features on their categorical/binned WoEs and IVs (Information Value) and then combine some of these binned categories together through a custom Python Class with fit_transform method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of the 4 training sets to be preprocessed using WoE\n",
    "X_train_prepr = X_train.copy()\n",
    "y_train_prepr = y_train.copy()\n",
    "X_test_prepr = X_test.copy()\n",
    "y_test_prepr = y_test.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze WoEs and IVs of discrete features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes 3 arguments: a dataframe (X_train_prepr), a string (column name), and a dataframe (y_train_prepr).\n",
    "# The function returns a dataframe as a result.\n",
    "def woe_discrete(df, cat_variabe_name, y_df):\n",
    "    df = pd.concat([df[cat_variabe_name], y_df], axis = 1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    df = df.sort_values(['WoE'])\n",
    "    df = df.reset_index(drop = True)\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df\n",
    "\n",
    "\n",
    "sns.set()\n",
    "# Function for plotting WoE across categoris that takes 2 arguments: a dataframe and a number\n",
    "def plot_by_woe(df_WoE, rotation_of_x_axis_labels = 0):\n",
    "    x = np.array(df_WoE.iloc[:, 0].apply(str))\n",
    "    y = df_WoE['WoE']\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.plot(x, y, marker = 'o', linestyle = 'dotted', color = 'k')\n",
    "    plt.xlabel(df_WoE.columns[0])\n",
    "    plt.ylabel('Weight of Evidence')\n",
    "    plt.title(str('Weight of Evidence by ' + df_WoE.columns[0]))\n",
    "    plt.xticks(rotation = rotation_of_x_axis_labels)    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'sub_grade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = woe_discrete(X_train_prepr, 'sub_grade', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine sub_grades:\n",
    "#  A1,A2,A3,A4,A5 as A\n",
    "#  B1,B2,B3,B4,B5 as B etc\n",
    "# Create a dictionary to map the sub_grades to the grades\n",
    "sub_grade_dict = {'A1':'A', 'A2':'A', 'A3':'A', 'A4':'A', 'A5':'A',\n",
    "                    'B1':'B', 'B2':'B', 'B3':'B', 'B4':'B', 'B5':'B',\n",
    "                    'C1':'C', 'C2':'C', 'C3':'C', 'C4':'C', 'C5':'C',\n",
    "                    'D1':'D', 'D2':'D', 'D3':'D', 'D4':'D', 'D5':'D',\n",
    "                    'E1':'E', 'E2':'E', 'E3':'E', 'E4':'E', 'E5':'E',\n",
    "                    'F1':'F', 'F2':'F', 'F3':'F', 'F4':'F', 'F5':'F',\n",
    "                    'G1':'G', 'G2':'G', 'G3':'G', 'G4':'G', 'G5':'G'}\n",
    "\n",
    "\n",
    "# Apply the dictionary to the sub_grade column\n",
    "X_train_prepr['sub_grade'] = X_train_prepr['sub_grade'].map(sub_grade_dict)\n",
    "X_test_prepr['sub_grade'] = X_test_prepr['sub_grade'].map(sub_grade_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the WoE for the new sub_grade column\n",
    "df = woe_discrete(X_train_prepr, 'sub_grade', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above graph that there is a continuous increase in WoE across the different grades. Therefore, we do not need to combine any features together and should leave all these 7 grades as they are"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### home_ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = woe_discrete(X_train_prepr, 'home_ownership', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verification_status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = woe_discrete(X_train_prepr, 'verification_status', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = woe_discrete(X_train_prepr, 'purpose', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df, 90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### addr_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = woe_discrete(X_train_prepr, 'addr_state', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df, 90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze WoEs and IVs of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to calculate WoE of continuous variables. This is same as the function we defined earlier for discrete variables.\n",
    "# The only difference are the 2 commented lines of code in the function that results in the df being sorted by continuous variable values\n",
    "def woe_ordered_continuous(df, continuous_variabe_name, y_df):\n",
    "    df = pd.concat([df[continuous_variabe_name], y_df], axis = 1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    #df = df.sort_values(['WoE'])\n",
    "    #df = df.reset_index(drop = True)\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepr['loan_amnt_factor'] = pd.cut(X_train_prepr['loan_amnt'], 10)\n",
    "df = woe_ordered_continuous(X_train_prepr, 'loan_amnt_factor', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = woe_ordered_continuous(X_train_prepr, 'term', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepr['int_rate_factor'] = pd.cut(X_train_prepr['int_rate'], 10)\n",
    "\n",
    "df = woe_ordered_continuous(X_train_prepr, 'int_rate_factor', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepr['installment_factor'] = pd.cut(X_train_prepr['installment'], 10)\n",
    "\n",
    "df = woe_ordered_continuous(X_train_prepr, 'installment_factor', y_train_prepr)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepr['annual_inc_factor'] = pd.cut(X_train_prepr['annual_inc'], 20)\n",
    "# \n",
    "df = woe_ordered_continuous(X_train_prepr, 'annual_inc_factor', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of them are < 350.000\n",
    "X_train_prepr_temp = X_train_prepr[X_train_prepr['annual_inc'] <= 350000].copy()\n",
    "\n",
    "X_train_prepr_temp['annual_inc_factor'] = pd.cut(X_train_prepr_temp['annual_inc'], 20)\n",
    "# \n",
    "df = woe_ordered_continuous(X_train_prepr_temp, 'annual_inc_factor', y_train_prepr[X_train_prepr_temp.index])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dti\n",
    "X_train_prepr['dti_factor'] = pd.cut(X_train_prepr['dti'], 20)\n",
    "df = woe_ordered_continuous(X_train_prepr, 'dti_factor', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fico_range_low and fico_range_high\n",
    "X_train_prepr['fico_range_low_factor'] = pd.cut(X_train_prepr['fico_range_low'], 20)\n",
    "df = woe_ordered_continuous(X_train_prepr, 'fico_range_low_factor', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fico_range_low and fico_range_high\n",
    "X_train_prepr['fico_range_high_factor'] = pd.cut(X_train_prepr['fico_range_high'], 20)\n",
    "df = woe_ordered_continuous(X_train_prepr, 'fico_range_high_factor', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepr['mort_acc_factor'] = pd.cut(X_train_prepr['mort_acc'], 10)\n",
    "df = woe_ordered_continuous(X_train_prepr, 'mort_acc_factor', y_train_prepr)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_prepr['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepr['age_factor'] = pd.cut(X_train_prepr['age'], 4)\n",
    "df = woe_ordered_continuous(X_train_prepr, 'age_factor', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepr['pay_status_factor'] = pd.cut(X_train_prepr['pay_status'], 10)\n",
    "df = woe_ordered_continuous(X_train_prepr, 'pay_status_factor', y_train_prepr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Class from WoE Binning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_categories = ['home_ownership:OTHER',  'verification_status:Not Verified',  'purpose:home_other_debt_moving_medical',  'loan_amnt:>32201', 'term:60', 'int_rate:>25.855', 'installment:>1071.177', 'annual_inc:>298505', 'dti:>39.9522', 'fico_range_low:>771.0', 'fico_range_high:>738.4', 'age:>60', 'pay_status:>0.2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "\n",
    "class WoE_Binning(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # sub_grade\n",
    "        # X_new = X.loc[:, 'sub_grade:A':'sub_grade:G']\n",
    "        # Define X_new to be the same as X\n",
    "        X_new = X.copy()\n",
    "        \n",
    "        # home ownership\n",
    "        X_new['home_ownership:OWN'] = X.loc[:,'home_ownership:OWN']\n",
    "        X_new['home_ownership:RENT'] = X.loc[:,'home_ownership:RENT']\n",
    "        X_new['home_ownership:OTHER'] = X.loc[:,'home_ownership:OTHER']\n",
    "        X_new['home_ownership:NONE'] = X.loc[:,'home_ownership:NONE']\n",
    "        X_new['home_ownership:ANY_MORTGAGE'] = sum([X['home_ownership:ANY'], X['home_ownership:MORTGAGE']])\n",
    "\n",
    "        # verification_status\n",
    "        X_new = pd.concat([X_new, X.loc[:, 'verification_status:Not Verified':'verification_status:Verified']], axis=1)\n",
    "        \n",
    "        # purpose\n",
    "        X_new['purpose:small_business'] = X.loc[:, 'purpose:small_business']\n",
    "        ## Let's combine features with low WoE\n",
    "        X_new['purpose:home_other_debt_moving_medical'] = sum([X['purpose:home_improvement'], X['purpose:other'], X['purpose:debt_consolidation'], X['purpose:moving']])\n",
    "        \n",
    "        # addr_state - inf IV let's not consider it\n",
    "\n",
    "        # loan_amnt\n",
    "        X_new['loan_amnt:<12701'] = np.where((X['loan_amnt'] <= 12701), 1, 0)\n",
    "        X_new['loan_amnt:12701-24401'] = np.where((X['loan_amnt'] > 12701) & (X['loan_amnt'] <= 24401), 1, 0)\n",
    "        X_new['loan_amnt:24401-32201'] = np.where((X['loan_amnt'] > 24401) & (X['loan_amnt'] <= 32201), 1, 0)\n",
    "        X_new['loan_amnt:>32201'] = np.where((X['loan_amnt'] > 32201), 1, 0)\n",
    "\n",
    "        # term\n",
    "        X_new['term:36'] = np.where((X['term'] == 36), 1, 0)\n",
    "        X_new['term:60'] = np.where((X['term'] == 60), 1, 0)\n",
    "\n",
    "        # int_rate\n",
    "        X_new['int_rate:<13.015'] = np.where((X['int_rate'] <= 13.015), 1, 0)\n",
    "        X_new['int_rate:13.015-20.719'] = np.where((X['int_rate'] > 13.015) & (X['int_rate'] <= 20.719), 1, 0)\n",
    "        X_new['int_rate:20.719-25.855'] = np.where((X['int_rate'] > 20.719) & (X['int_rate'] <= 25.855), 1, 0)\n",
    "        X_new['int_rate:>25.855'] = np.where((X['int_rate'] > 25.855), 1, 0)\n",
    "\n",
    "        # installment\n",
    "        X_new['installment:<327.987'] = np.where((X['installment'] <= 327.987), 1, 0)\n",
    "        X_new['installment:327.987-1071.177'] = np.where((X['installment'] > 327.987) & (X['installment'] <= 1071.177), 1, 0)\n",
    "        X_new['installment:>1071.177'] = np.where((X['installment'] > 1071.177), 1, 0)\n",
    "\n",
    "        # annual_inc\n",
    "        X_new['annual_inc:missing'] = np.where(X['annual_inc'].isnull(), 1, 0)\n",
    "        X_new['annual_inc:<75357'] = np.where((X['annual_inc'] <= 75357), 1, 0)\n",
    "        X_new['annual_inc:75357-161183'] = np.where((X['annual_inc'] > 75357) & (X['annual_inc'] <= 161183), 1, 0)\n",
    "        X_new['annual_inc:161183-195513'] = np.where((X['annual_inc'] > 161183) & (X['annual_inc'] <= 195513), 1, 0)\n",
    "        X_new['annual_inc:195513-247009]'] = np.where((X['annual_inc'] > 195513) & (X['annual_inc'] <= 247009), 1, 0)\n",
    "        X_new['annual_inc:247009-264174]]'] = np.where((X['annual_inc'] > 247009) & (X['annual_inc'] <= 264174), 1, 0)\n",
    "        X_new['annual_inc:264174-281339]]'] = np.where((X['annual_inc'] > 264174) & (X['annual_inc'] <= 281339), 1, 0)\n",
    "        X_new['annual_inc:281339-298505]]'] = np.where((X['annual_inc'] > 281339) & (X['annual_inc'] <= 298505), 1, 0)\n",
    "        X_new['annual_inc:>298505]]'] = np.where((X['annual_inc'] > 298505), 1, 0)\n",
    "\n",
    "        # dti\n",
    "        X_new['dti:<19.977'] = np.where((X['dti'] <= 19.977), 1, 0)\n",
    "        X_new['dti:19.977-37.455'] = np.where((X['dti'] > 19.977) & (X['dti'] <= 37.455), 1, 0)\n",
    "        X_new['dti:37.455-39.9522'] = np.where((X['dti'] > 37.455) & (X['dti'] <= 39.9522), 1, 0)\n",
    "        X_new['dti:>39.9522'] = np.where((X['dti'] > 39.9522), 1, 0)\n",
    "\n",
    "        # fico_range_low\n",
    "        X_new['fico_range_low:<697.01'] = np.where((X['fico_range_low'] <= 697.01), 1, 0)\n",
    "        X_new['fico_range_low:697.01-771.0'] = np.where((X['fico_range_low'] > 697.01) & (X['fico_range_low'] <= 771.0), 1, 0)\n",
    "        X_new['fico_range_low:>771.0'] = np.where((X['fico_range_low'] > 771.0), 1, 0)\n",
    "\n",
    "        # fico_range_high\n",
    "        X_new['fico_range_high:<691.9'] = np.where((X['fico_range_high'] <= 691.9), 1, 0)\n",
    "        X_new['fico_range_high:691.9-738.4'] = np.where((X['fico_range_high'] > 691.9) & (X['fico_range_high'] <= 738.4), 1, 0)\n",
    "        X_new['fico_range_high:>738.4'] = np.where((X['fico_range_high'] > 738.4), 1, 0)\n",
    "\n",
    "        # mort_acc - do not consider it\n",
    "\n",
    "        # age\n",
    "        X_new['age:<30'] = np.where((X['age'] <= 30), 1, 0)\n",
    "        X_new['age:30-60'] = np.where((X['age'] > 30) & (X['age'] <= 60), 1, 0)\n",
    "        X_new['age:>60'] = np.where((X['age'] > 60) , 1, 0)\n",
    "        \n",
    "        # pay_status\n",
    "        X_new['pay_status:<-0.9'] = np.where((X['pay_status'] <= -0.9), 1, 0)\n",
    "        X_new['pay_status:-0.9-0.2'] = np.where((X['pay_status'] > -0.9) & (X['pay_status'] <= 0.2), 1, 0)\n",
    "        X_new['pay_status:>0.2'] = np.where((X['pay_status'] > 0.2), 1, 0)\n",
    "        return X_new\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PD Model Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconfirm shape of the 4 datasets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define modeling pipeline\n",
    "reg = LogisticRegression(max_iter=1000, class_weight = 'balanced')\n",
    "woe_transform = WoE_Binning(X)\n",
    "pipeline = Pipeline(steps=[('woe', woe_transform), ('model', reg)])\n",
    "\n",
    "# define cross-validation criteria. RepeatedStratifiedKFold automatially takes care of the class imbalance while splitting\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# fit and evaluate the logistic regression pipeline with cross-validation as defined in cv\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring = 'roc_auc', cv = cv)\n",
    "AUROC = np.mean(scores)\n",
    "GINI = AUROC * 2 - 1\n",
    "\n",
    "# print the mean AUROC score and Gini\n",
    "print('Mean AUROC: %.4f' % (AUROC))\n",
    "print('Gini: %.4f' % (GINI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.info()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty impressive scores for the first time, now let's fit the pipeline on the whole training set\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create a transformed training set through our WoE_Binning custom class\n",
    "X_train_woe_transformed = woe_transform.fit_transform(X_train)\n",
    "# Store the column names in X_train as a list\n",
    "feature_name = X_train_woe_transformed.columns.values\n",
    "# Create a summary table of our logistic regression model\n",
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "# Create a new column in the dataframe, called 'Coefficients', with row values the transposed coefficients from the 'LogisticRegression' model\n",
    "summary_table['Coefficients'] = np.transpose(pipeline['model'].coef_)\n",
    "# Increase the index of every row of the dataframe with 1 to store our model intercept in 1st row\n",
    "summary_table.index = summary_table.index + 1\n",
    "# Assign our model intercept to this new row\n",
    "summary_table.loc[0] = ['Intercept', pipeline['model'].intercept_[0]]\n",
    "# Sort the dataframe by index\n",
    "summary_table.sort_index(inplace = True)\n",
    "summary_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make preditions on our test set\n",
    "y_hat_test = pipeline.predict(X_test)\n",
    "# get the predicted probabilities\n",
    "y_hat_test_proba = pipeline.predict_proba(X_test)\n",
    "# select the probabilities of only the positive class (class 1 - default) \n",
    "y_hat_test_proba = y_hat_test_proba[:][: , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now create a new DF with actual classes and the predicted probabilities\n",
    "# create a temp y_test DF to reset its index to allow proper concaternation with y_hat_test_proba\n",
    "y_test_temp = y_test.copy()\n",
    "y_test_temp.reset_index(drop = True, inplace = True)\n",
    "y_test_proba = pd.concat([y_test_temp, pd.DataFrame(y_hat_test_proba)], axis = 1)\n",
    "# check the shape to make sure the number of rows is same as that in y_test\n",
    "y_test_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "y_test_proba.columns = ['y_test_class_actual', 'y_hat_test_proba']\n",
    "# Makes the index of one dataframe equal to the index of another dataframe.\n",
    "y_test_proba.index = X_test.index\n",
    "y_test_proba.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix and AUROC on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a threshold value to differentiate good with bad\n",
    "tr = 0.5\n",
    "# crate a new column for the predicted class based on predicted probabilities and threshold\n",
    "# We will determine this optimat threshold later in this project\n",
    "y_test_proba['y_test_class_predicted'] = np.where(y_test_proba['y_hat_test_proba'] > tr, 1, 0)\n",
    "# create the confusion matrix\n",
    "confusion_matrix(y_test_proba['y_test_class_actual'], y_test_proba['y_test_class_predicted'], normalize = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values required to plot a ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n",
    "# plot the ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "# plot a secondary diagonal line, with dashed line style and black color to represent a no-skill classifier\n",
    "plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Area Under the Receiver Operating Characteristic Curve (AUROC) on our test set\n",
    "AUROC = roc_auc_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n",
    "AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Gini from AUROC\n",
    "Gini = AUROC * 2 - 1\n",
    "Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a PR curve\n",
    "# calculate the no skill line as the proportion of the positive class\n",
    "no_skill = len(y_test[y_test == 1]) / len(y)\n",
    "# plot the no skill precision-recall curve\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "\n",
    "# calculate inputs for the PR curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n",
    "# plot PR curve\n",
    "plt.plot(recall, precision, marker='.', label='Logistic')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.title('PR curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PR AUC\n",
    "auc_pr = auc(recall, precision)\n",
    "auc_pr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the Model - Scorecard Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new dataframe with one column. Its values are the values from the 'reference_categories' list. We name it 'Feature name'.\n",
    "df_ref_categories = pd.DataFrame(ref_categories, columns = ['Feature name'])\n",
    "# We create a second column, called 'Coefficients', which contains only 0 values.\n",
    "df_ref_categories['Coefficients'] = 0\n",
    "df_ref_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenates two dataframes.\n",
    "df_scorecard = pd.concat([summary_table, df_ref_categories])\n",
    "# We reset the index of a dataframe.\n",
    "df_scorecard.reset_index(inplace = True)\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column, called 'Original feature name', which contains the value of the 'Feature name' column, up to the column symbol.\n",
    "df_scorecard['Original feature name'] = df_scorecard['Feature name'].str.split(':').str[0]\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the min and max threshholds for our scorecard\n",
    "min_score = 300\n",
    "max_score = 850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of the minimum coefficients of each category within the original feature name\n",
    "min_sum_coef = df_scorecard.groupby('Original feature name')['Coefficients'].min().sum()\n",
    "# calculate the sum of the maximum coefficients of each category within the original feature name\n",
    "max_sum_coef = df_scorecard.groupby('Original feature name')['Coefficients'].max().sum()\n",
    "# create a new columns that has the imputed calculated Score based on the multiplication of the coefficient by the ratio of the differences between\n",
    "# maximum & minimum score and maximum & minimum sum of cefficients.\n",
    "df_scorecard['Score - Calculation'] = df_scorecard['Coefficients'] * (max_score - min_score) / (max_sum_coef - min_sum_coef)\n",
    "# update the calculated score of the Intercept (i.e. the default score for each loan)\n",
    "df_scorecard.loc[0, 'Score - Calculation'] = ((df_scorecard.loc[0,'Coefficients'] - min_sum_coef) / (max_sum_coef - min_sum_coef)) * (max_score - min_score) + min_score\n",
    "# round the values of the 'Score - Calculation' column and store them in a new column\n",
    "df_scorecard['Score - Preliminary'] = df_scorecard['Score - Calculation'].round()\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the min and max possible scores of our scorecard\n",
    "min_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Preliminary'].min().sum()\n",
    "max_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Preliminary'].max().sum()\n",
    "print(min_sum_score_prel)\n",
    "print(max_sum_score_prel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so both our min and max scores are out by +1. we need to manually adjust this\n",
    "# Which one? We'll evaluate based on the rounding differences of the minimum category within each Original Feature Name.\n",
    "pd.options.display.max_rows = 102\n",
    "df_scorecard['Difference'] = df_scorecard['Score - Preliminary'] - df_scorecard['Score - Calculation']\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look like we can get by deducting 1 from the Intercept\n",
    "df_scorecard['Score - Final'] = df_scorecard['Score - Preliminary']\n",
    "df_scorecard.loc[0, 'Score - Final'] = 598\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recheck min and max possible scores\n",
    "print(df_scorecard.groupby('Original feature name')['Score - Final'].min().sum())\n",
    "print(df_scorecard.groupby('Original feature name')['Score - Final'].max().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating credit scores for all observations in the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create a transformed test set through our WoE_Binning custom class\n",
    "X_test_woe_transformed = woe_transform.fit_transform(X_test)\n",
    "# insert an Intercept column in its beginning to align with the # of rows in scorecard\n",
    "X_test_woe_transformed.insert(0, 'Intercept', 1)\n",
    "X_test_woe_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of our final scorecard scores\n",
    "scorecard_scores = df_scorecard['Score - Final']\n",
    "# check the shapes of test set and scorecard before doing matrix dot multiplication\n",
    "print(X_test_woe_transformed.shape)\n",
    "print(scorecard_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the test set has 17 less columns than the rows in scorecard due to the reference categories\n",
    "# since the reference categories will always be scored as 0 based on the scorecard, it is safe to add these categories to the end of test set with 0 values\n",
    "X_test_woe_transformed = pd.concat([X_test_woe_transformed, pd.DataFrame(dict.fromkeys(ref_categories, [0] * len(X_test_woe_transformed)), \n",
    "                                                                         index = X_test_woe_transformed.index)], axis = 1)\n",
    "# Need to reshape scorecard_scores so that it is (102,1) to allow for matrix dot multiplication\n",
    "scorecard_scores = scorecard_scores.values.reshape(102, 1)\n",
    "print(X_test_woe_transformed.shape)\n",
    "print(scorecard_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix dot multiplication of test set with scorecard scores\n",
    "y_scores = X_test_woe_transformed.dot(scorecard_scores)\n",
    "y_scores.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
